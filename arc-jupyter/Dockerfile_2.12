FROM jupyter/scipy-notebook

USER root

# Versions
ARG ARC_JUPYTER_VERSION
ARG SPARK_VERSION
ARG HADOOP_VERSION

# test to ensure all arguments have values then set environment variable
RUN test -n "$ARC_JUPYTER_VERSION"
ENV ARC_JUPYTER_VERSION $ARC_JUPYTER_VERSION
RUN test -n "$SPARK_VERSION"
ENV SPARK_VERSION $SPARK_VERSION
RUN test -n "$HADOOP_VERSION"
ENV HADOOP_VERSION $HADOOP_VERSION

ENV SCALA_VERSION         2.12
ENV SPARK_HOME            /usr/local/spark
ENV HADOOP_HOME           /opt/hadoop
ENV JAVA_HOME             /usr
ENV SPARK_DOWNLOAD_URL    http://apache.mirror.amaze.com.au/spark
ENV SPARK_CHECKSUM_URL    https://www.apache.org/dist/spark
ENV SPARK_KEYS_URL        https://www.apache.org/dist/spark/KEYS
ENV HADOOP_DOWNLOAD_URL   http://apache.mirror.amaze.com.au/hadoop/common
ENV HADOOP_CHECKSUM_URL   https://www.apache.org/dist/hadoop/common
ENV HADOOP_KEYS_URL       https://www.apache.org/dist/hadoop/common/KEYS
ENV JAVA_OPTS             "-Xmx1g"
ENV BASE_JAVA_OPTS        "-XX:+UseG1GC -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
ENV PYTHONPATH            $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip
ENV SPARK_OPTS            --driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info

RUN apt-get update && \
  apt-get install --no-install-recommends -y openjdk-8-jre-headless ca-certificates-java wget gpg gpg-agent && \
  rm -rf /var/lib/apt/lists/*

# add spark-without-hadoop
RUN mkdir -p ${SPARK_HOME} && \
  wget ${SPARK_DOWNLOAD_URL}/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-without-hadoop-scala-2.12.tgz && \
  wget ${SPARK_CHECKSUM_URL}/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-without-hadoop-scala-2.12.tgz.asc && \
  wget ${SPARK_KEYS_URL} && \
  gpg --import KEYS && \
  gpg --verify spark-${SPARK_VERSION}-bin-without-hadoop-scala-2.12.tgz.asc && \
  gunzip -c spark-${SPARK_VERSION}-bin-without-hadoop-scala-2.12.tgz | tar -xf - -C $SPARK_HOME --strip-components=1 && \
  rm -f spark-${SPARK_VERSION}-bin-without-hadoop-scala-2.12.* && \
  rm KEYS

# add hadoop
RUN mkdir -p ${HADOOP_HOME} && \
  wget ${HADOOP_DOWNLOAD_URL}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz && \
  wget ${HADOOP_CHECKSUM_URL}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz.asc && \
  wget ${HADOOP_KEYS_URL} && \
  gpg --import KEYS && \
  gpg --verify hadoop-${HADOOP_VERSION}.tar.gz.asc && \
  gunzip -c hadoop-${HADOOP_VERSION}.tar.gz | tar -xf - -C $HADOOP_HOME --strip-components=1 && \
  rm -f hadoop*.tar.gz* && \
  rm KEYS

# link hadoop to spark as per https://spark.apache.org/docs/latest/hadoop-provided.html
RUN echo "export SPARK_DIST_CLASSPATH=\$(/opt/hadoop/bin/hadoop classpath)" >> ${SPARK_HOME}/conf/spark-env.sh

# create symlink for Jupyter
RUN cd /usr/local && ln -s spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} spark

# remove gpg 
RUN apt-get remove -y --purge gpg gpg-agent && \
  rm -r /home/jovyan/.gnupg

# switch to the notebook user
USER $NB_USER

# get coursier to download additional jars to be accessed from pyspark
RUN cd /tmp && \
  wget -P /tmp https://git.io/coursier-cli && \
  chmod +x /tmp/coursier-cli && \
  /tmp/coursier-cli fetch \
  --force-version com.fasterxml.jackson.core:jackson-databind:2.6.7.1 \
  --force-version org.json4s:json4s-ast_${SCALA_VERSION}:3.5.3 \
  --force-version org.json4s:json4s-core_${SCALA_VERSION}:3.5.3 \
  --force-version org.json4s:json4s-jackson_${SCALA_VERSION}:3.5.3 \
  --force-version org.json4s:json4s-scalap_${SCALA_VERSION}:3.5.3 \
  --force-version com.google.guava:guava:14.0.1 \
  --force-version org.slf4j:slf4j-log4j12:1.7.16 \
  --exclude org.slf4j:slf4j-nop \  
  com.facebook.presto:presto-jdbc:0.221 \
  com.microsoft.sqlserver:mssql-jdbc:7.2.2.jre8 \
  mysql:mysql-connector-java:8.0.16 \
  org.apache.hadoop:hadoop-aws:${HADOOP_VERSION} \
  org.apache.hadoop:hadoop-azure:${HADOOP_VERSION} \
  org.postgresql:postgresql:42.2.6 

# move the jars to the spark/jars path for easy resolution
# also copy local ones for development
RUN find /home/jovyan/.cache/coursier -name "*.jar" -print0 | xargs -0 -I {} mv {} ${SPARK_HOME}/jars

# download arc library and dependencies
RUN cd /tmp && \
  /tmp/coursier-cli bootstrap \
  --embed-files=false \
  --force-version com.fasterxml.jackson.core:jackson-databind:2.6.7.1 \
  --force-version org.json4s:json4s-ast_${SCALA_VERSION}:3.5.3 \
  --force-version org.json4s:json4s-core_${SCALA_VERSION}:3.5.3 \
  --force-version org.json4s:json4s-jackson_${SCALA_VERSION}:3.5.3 \
  --force-version org.json4s:json4s-scalap_${SCALA_VERSION}:3.5.3 \
  --force-version com.google.guava:guava:14.0.1 \
  --force-version org.slf4j:slf4j-log4j12:1.7.25 \
  --exclude org.slf4j:slf4j-nop \
  ai.tripl:arc-jupyter_${SCALA_VERSION}:${ARC_JUPYTER_VERSION} \
  ai.tripl:arc-deltalake-pipeline-plugin_${SCALA_VERSION}:1.2.0 \
  ai.tripl:arc-deltaperiod-config-plugin_${SCALA_VERSION}:1.0.1 \
  ai.tripl:arc-graph-pipeline-plugin_${SCALA_VERSION}:1.0.1 \
  ai.tripl:arc-kafka-pipeline-plugin_${SCALA_VERSION}:1.0.1 \
  ai.tripl:arc-mongodb-pipeline-plugin_${SCALA_VERSION}:1.0.2 \
  com.facebook.presto:presto-jdbc:0.221 \
  com.microsoft.sqlserver:mssql-jdbc:7.2.2.jre8 \
  mysql:mysql-connector-java:8.0.16 \
  org.apache.hadoop:hadoop-aws:${HADOOP_VERSION} \
  org.apache.hadoop:hadoop-azure:${HADOOP_VERSION} \
  org.postgresql:postgresql:42.2.6 \  
  -o arc && \
  ./arc --install --force && \
  rm /tmp/arc && \
  rm /tmp/coursier-cli  

# add Download as: Arc (.json) to jupyter notebook
RUN pip install git+https://github.com/tripl-ai/nb_extension_arcexport.git

# override default run command to allow JAVA_OPTS injection
COPY arc-jupyter/kernel.json /home/jovyan/.local/share/jupyter/kernels/arc/kernel.json

# Install pyarrow
RUN conda install --quiet -y 'pyarrow' && \
  conda clean --all -f -y && \
  fix-permissions $CONDA_DIR && \
  fix-permissions /home/$NB_USER

# add the execution time extension
RUN pip install jupyter_contrib_nbextensions && \
  jupyter contrib nbextension install --user && \
  jupyter nbextensions_configurator disable --user && \
  jupyter nbextension enable execute_time/ExecuteTime

# add the jupyterlab-git extension
RUN pip install --upgrade jupyterlab-git && \
  jupyter lab build

# ui tweaks
# css to maximise screen realestate
COPY arc-jupyter/custom.css /home/jovyan/.jupyter/custom/custom.css
# js to set code formatting for arc commmands
COPY arc-jupyter/custom.js /home/jovyan/.jupyter/custom/custom.js
# copy in settings to fix tabsize
COPY arc-jupyter/notebook.json /home/jovyan/.jupyter/nbconfig

# disable default save data with notebooks
COPY arc-jupyter/scrub_output_pre_save.py /tmp/scrub_output_pre_save.py
RUN cat /tmp/scrub_output_pre_save.py >> /etc/jupyter/jupyter_notebook_config.py

# set permissions
USER root
RUN chown -R jovyan:users /home/jovyan
USER $NB_UID
