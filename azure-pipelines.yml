# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master

jobs:
- job: build

  pool:
    vmImage: 'ubuntu-latest'

  variables:
    arc_version: '3.6.2'
    arc-jupyter_version: '3.11.0'
    spark_version: '3.0.1'
    hadoop_version: '3.2.0'
    scala_version: '2.12'
    spark_checksum_url: 'https://www.apache.org/dist/spark'
    spark_keys_url: 'https://www.apache.org/dist/spark/KEYS'

  timeoutInMinutes: 720
  steps:
  - script: |
      docker login --username $(DOCKER_HUB_USERNAME) --password $(DOCKER_HUB_PASSWORD)
    displayName: 'login to docker hub to allow push (https://hub.docker.com/u/triplai)'

  # Download the pgp keys from azure secure library
  - task: DownloadSecureFile@1
    name: githubToken
    displayName: 'Get GH_TOKEN.txt from Azure Secure Library'
    inputs:
      secureFile: "GH_TOKEN.txt"

  - script: |
      cat $(githubToken.secureFilePath) | docker login ghcr.io -u seddonm1 --password-stdin
    displayName: 'login to github package registry hub to allow push to tripl.ai packages'

  # this script builds the arc image using the spark k8s image
  - script: |
      export ARC_VERSION=$(arc_version)
      export SPARK_VERSION=$(spark_version)
      export SCALA_VERSION=$(scala_version)
      export HADOOP_VERSION=$(hadoop_version)
      export ARC_JUPYTER_VERSION=$(arc-jupyter_version)
      export ARC_IMAGE_VERSION=$(cat arc/version)
      export ARC_JUPYTER_IMAGE_VERSION=$(cat arc-jupyter/version)
      export FROM_IMAGE=ghcr.io/tripl-ai/spark:spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}

      # if manifest exists then exit with failure else build and push
      if DOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect ghcr.io/tripl-ai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION} >/dev/null; then
        echo "skip due to image already exists: ghcr.io/tripl-ai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION}"
        exit 0
      else
        docker build . \
          -f arc/Dockerfile \
          --build-arg FROM_IMAGE \
          --build-arg ARC_VERSION \
          --build-arg SPARK_VERSION \
          --build-arg HADOOP_VERSION \
          --build-arg SCALA_VERSION \
          -t triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION}

        docker push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION}

        docker tag triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION} triplai/arc:latest
        docker push triplai/arc:latest

        # tag push to github package registry
        docker tag triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION} ghcr.io/tripl-ai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION}
        docker push ghcr.io/tripl-ai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION}
        docker tag triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION} ghcr.io/tripl-ai/arc:latest
        docker push ghcr.io/tripl-ai/arc:latest
      fi
    displayName: 'build triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION}'
    condition: always()

  # this script builds the arc-jupyter image using the arc image
  - script: |
      export ARC_VERSION=$(arc_version)
      export SPARK_VERSION=$(spark_version)
      export SCALA_VERSION=$(scala_version)
      export HADOOP_VERSION=$(hadoop_version)
      export ARC_JUPYTER_VERSION=$(arc-jupyter_version)
      export ARC_IMAGE_VERSION=$(cat arc/version)
      export ARC_JUPYTER_IMAGE_VERSION=$(cat arc-jupyter/version)
      export FROM_IMAGE=triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_IMAGE_VERSION}

      if DOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect ghcr.io/tripl-ai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION} >/dev/null; then
        echo "skip due to image already exists: ghcr.io/tripl-ai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION}"
        exit 0
      else
        docker build . \
        -f arc-jupyter/Dockerfile \
        --build-arg FROM_IMAGE \
        --build-arg PASSWD=$(PASSWD) \
        --build-arg ARC_JUPYTER_VERSION \
        -t triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION}

        docker push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION}

        docker tag triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION} triplai/arc-jupyter:latest
        docker push triplai/arc-jupyter:latest

        # tag push to github package registry
        docker tag triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION} ghcr.io/tripl-ai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION}
        docker push ghcr.io/tripl-ai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION}
        docker tag triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION} ghcr.io/tripl-ai/arc-jupyter:latest
        docker push ghcr.io/tripl-ai/arc-jupyter:latest
      fi
    displayName: 'build triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${ARC_JUPYTER_IMAGE_VERSION}'
    condition: always()
